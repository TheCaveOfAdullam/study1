{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNywWQhUR8WPeRLfGNtO9r0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheCaveOfAdullam/study1/blob/main/pruningApple1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u05w_BpjDU8K",
        "outputId": "941e5590-df3c-4849-c5a1-e11745c1c7ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow_model_optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8FSevUbYBYo",
        "outputId": "a0c72186-68a7-49c5-e717-3fb12df24e46"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_model_optimization\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (0.1.8)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.25.2)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.16.0)\n",
            "Installing collected packages: tensorflow_model_optimization\n",
            "Successfully installed tensorflow_model_optimization-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import psutil\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_optimization as tfmot"
      ],
      "metadata": {
        "id": "gXA7Vruq1TGQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 경로 설정\n",
        "base_dir = '/content/drive/MyDrive/ship_data'\n",
        "categories = ['normal', 'fault_BB', 'fault_RI', 'fault_SM']\n",
        "\n",
        "# 데이터 로드 및 전처리 함수 정의\n",
        "def load_data(base_dir, split):\n",
        "    X = []\n",
        "    y = []\n",
        "    split_dir = os.path.join(base_dir, split)\n",
        "    for category in categories:\n",
        "        category_dir = os.path.join(split_dir, category)\n",
        "        for file in os.listdir(category_dir):\n",
        "            file_path = os.path.join(category_dir, file)\n",
        "            data = pd.read_csv(file_path, header=None).values\n",
        "            data = pd.to_numeric(data.flatten(), errors='coerce').reshape(-1, data.shape[1])\n",
        "            data = np.nan_to_num(data).astype('float32')  # NaN 값을 0으로 대체하고, float32로 변환\n",
        "            X.append(data)\n",
        "            y.append(category)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# 데이터 로드\n",
        "X_train, y_train = load_data(base_dir, 'train')\n",
        "X_val, y_val = load_data(base_dir, 'validation')\n",
        "X_test, y_test = load_data(base_dir, 'test')"
      ],
      "metadata": {
        "id": "XU0GjLCz1TI5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 차원 변경 (CNN 입력 형식에 맞게)\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_val = np.expand_dims(X_val, axis=-1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder.transform(y_val)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# 원-핫 인코딩\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "y_val_categorical = to_categorical(y_val_encoded)\n",
        "y_test_categorical = to_categorical(y_test_encoded)"
      ],
      "metadata": {
        "id": "riB6G9bu1TLx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 CNN 모델 정의\n",
        "original_model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(categories), activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "original_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SbODiro81TOi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 모델 학습\n",
        "original_history = original_model.fit(X_train, y_train_categorical, epochs=10, batch_size=32, validation_data=(X_val, y_val_categorical))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmM7iSPX1TRr",
        "outputId": "34daa397-2f35-452d-84b1-779892573da4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "219/219 [==============================] - 78s 350ms/step - loss: 1.6088 - accuracy: 0.4753 - val_loss: 1.2668 - val_accuracy: 0.5869\n",
            "Epoch 2/10\n",
            "219/219 [==============================] - 76s 346ms/step - loss: 1.0171 - accuracy: 0.5528 - val_loss: 0.5975 - val_accuracy: 0.7246\n",
            "Epoch 3/10\n",
            "219/219 [==============================] - 76s 346ms/step - loss: 0.7335 - accuracy: 0.6051 - val_loss: 0.4084 - val_accuracy: 0.8623\n",
            "Epoch 4/10\n",
            "219/219 [==============================] - 76s 347ms/step - loss: 0.6532 - accuracy: 0.6411 - val_loss: 0.2796 - val_accuracy: 0.8725\n",
            "Epoch 5/10\n",
            "219/219 [==============================] - 77s 350ms/step - loss: 0.6459 - accuracy: 0.6653 - val_loss: 0.2884 - val_accuracy: 0.8920\n",
            "Epoch 6/10\n",
            "219/219 [==============================] - 76s 349ms/step - loss: 0.6194 - accuracy: 0.6823 - val_loss: 0.2207 - val_accuracy: 0.9844\n",
            "Epoch 7/10\n",
            "219/219 [==============================] - 76s 348ms/step - loss: 0.6092 - accuracy: 0.6945 - val_loss: 0.2239 - val_accuracy: 0.9914\n",
            "Epoch 8/10\n",
            "219/219 [==============================] - 77s 350ms/step - loss: 0.5791 - accuracy: 0.7192 - val_loss: 0.2432 - val_accuracy: 0.9937\n",
            "Epoch 9/10\n",
            "219/219 [==============================] - 76s 349ms/step - loss: 0.5843 - accuracy: 0.7194 - val_loss: 0.2384 - val_accuracy: 0.9617\n",
            "Epoch 10/10\n",
            "219/219 [==============================] - 77s 350ms/step - loss: 0.5867 - accuracy: 0.7199 - val_loss: 0.2033 - val_accuracy: 0.9914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 모델 평가\n",
        "original_val_loss, original_val_accuracy = original_model.evaluate(X_val, y_val_categorical)\n",
        "original_test_loss, original_test_accuracy = original_model.evaluate(X_test, y_test_categorical)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BO5tx7V1TT6",
        "outputId": "7bb6330a-872f-48ff-9914-1ce646f9bbac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 3s 72ms/step - loss: 0.2033 - accuracy: 0.9914\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.2016 - accuracy: 0.9914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 모델 사이즈 확인 및 저장\n",
        "original_model.save('original_model.h5')\n",
        "original_model_size = os.path.getsize('original_model.h5') / (1024 * 1024)  # 모델 사이즈를 MB 단위로 변환\n",
        "print(f\"Original Model Size: {original_model_size:.2f} MB\")\n",
        "\n",
        "# 원본 모델 메모리 사용량 확인\n",
        "process = psutil.Process(os.getpid())\n",
        "original_memory_usage = process.memory_info().rss / (1024 * 1024)  # 메모리 사용량을 MB 단위로 변환\n",
        "print(f\"Original Memory Usage: {original_memory_usage:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvRrkaow1TWa",
        "outputId": "2e5604e9-09bc-404a-e850-b54170b59ef6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Model Size: 439.50 MB\n",
            "Original Memory Usage: 7503.37 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 모델 추론 시간 측정\n",
        "start_time = time.time()\n",
        "original_y_pred_categorical = original_model.predict(X_test)\n",
        "end_time = time.time()\n",
        "original_inference_time = end_time - start_time\n",
        "print(f\"Original Inference Time: {original_inference_time:.2f} seconds\")\n",
        "\n",
        "original_y_pred = np.argmax(original_y_pred_categorical, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evlpIh9j1TZT",
        "outputId": "ea72909d-ad4a-4a7b-9aa6-e2673e109a3d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 3s 66ms/step\n",
            "Original Inference Time: 2.97 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 혼동 행렬 및 성능 지표 출력 (검증 데이터)\n",
        "original_y_pred_val = original_model.predict(X_val)\n",
        "original_y_pred_val_classes = np.argmax(original_y_pred_val, axis=1)\n",
        "\n",
        "original_conf_matrix_val = confusion_matrix(y_val_encoded, original_y_pred_val_classes)\n",
        "original_class_report_val = classification_report(y_val_encoded, original_y_pred_val_classes, target_names=categories)\n",
        "\n",
        "print(\"Original Confusion Matrix (Validation):\")\n",
        "print(original_conf_matrix_val)\n",
        "print(\"\\nOriginal Classification Report (Validation):\")\n",
        "print(original_class_report_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7RKAaoB1TcB",
        "outputId": "854a3e7f-e3f2-4038-b8ec-e6e23b6732b3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 3s 67ms/step\n",
            "Original Confusion Matrix (Validation):\n",
            "[[176   0   0   0]\n",
            " [  0 176   0   0]\n",
            " [  9   0 165   2]\n",
            " [  0   0   0 750]]\n",
            "\n",
            "Original Classification Report (Validation):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal       0.95      1.00      0.98       176\n",
            "    fault_BB       1.00      1.00      1.00       176\n",
            "    fault_RI       1.00      0.94      0.97       176\n",
            "    fault_SM       1.00      1.00      1.00       750\n",
            "\n",
            "    accuracy                           0.99      1278\n",
            "   macro avg       0.99      0.98      0.99      1278\n",
            "weighted avg       0.99      0.99      0.99      1278\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 혼동 행렬 및 성능 지표 출력 (테스트 데이터)\n",
        "original_conf_matrix_test = confusion_matrix(y_test_encoded, original_y_pred)\n",
        "original_class_report_test = classification_report(y_test_encoded, original_y_pred, target_names=categories)\n",
        "\n",
        "print(\"Original Confusion Matrix (Test):\")\n",
        "print(original_conf_matrix_test)\n",
        "print(\"\\nOriginal Classification Report (Test):\")\n",
        "print(original_class_report_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUMsO9LU1Tep",
        "outputId": "b3f1db55-1b2f-4521-98b3-b3d5ceff4f41"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Confusion Matrix (Test):\n",
            "[[176   0   0   0]\n",
            " [  0 176   0   0]\n",
            " [  7   0 165   4]\n",
            " [  0   0   0 750]]\n",
            "\n",
            "Original Classification Report (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal       0.96      1.00      0.98       176\n",
            "    fault_BB       1.00      1.00      1.00       176\n",
            "    fault_RI       1.00      0.94      0.97       176\n",
            "    fault_SM       0.99      1.00      1.00       750\n",
            "\n",
            "    accuracy                           0.99      1278\n",
            "   macro avg       0.99      0.98      0.99      1278\n",
            "weighted avg       0.99      0.99      0.99      1278\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Structured Pruning 적용 함수 정의\n",
        "def apply_structured_pruning(model, pruning_percentage=50):\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, Conv1D):\n",
        "            weights, biases = layer.get_weights()\n",
        "            num_filters = weights.shape[-1]\n",
        "            num_prune = int(num_filters * pruning_percentage / 100)\n",
        "\n",
        "            # Compute the L1 norm of the filters\n",
        "            filter_norms = np.sum(np.abs(weights), axis=(0, 1))\n",
        "            prune_indices = np.argsort(filter_norms)[:num_prune]\n",
        "\n",
        "            # Set the weights of the pruned filters to zero\n",
        "            for idx in prune_indices:\n",
        "                weights[:, :, idx] = 0\n",
        "\n",
        "            layer.set_weights([weights, biases])\n",
        "\n",
        "# 원본 모델 복사 (모델을 재사용하기 위해)\n",
        "pruned_model = tf.keras.models.clone_model(original_model)\n",
        "\n",
        "# Build the pruned model (this is the key change)\n",
        "pruned_model.build(input_shape=original_model.input_shape)\n",
        "\n",
        "# Now you can set the weights\n",
        "pruned_model.set_weights(original_model.get_weights())\n",
        "\n",
        "apply_structured_pruning(pruned_model, pruning_percentage=50)\n",
        "\n",
        "# 프루닝 후 모델 컴파일\n",
        "# Pass 'adam' as a string identifier instead of an Adam object\n",
        "pruned_model.compile(optimizer='adam',\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "S0G0v7kW1ThT"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 프루닝된 모델 재학습\n",
        "pruned_history = pruned_model.fit(X_train, y_train_categorical, epochs=10, batch_size=32, validation_data=(X_val, y_val_categorical))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "-TUF95Sq1TkM",
        "outputId": "75759ac5-ac3f-4797-8d39-5401e251ad22"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-25d35ab7c910>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 프루닝된 모델 재학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpruned_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpruned_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_categorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3976\u001b[0m         \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3977\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3978\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   3979\u001b[0m                 \u001b[0;34m\"You must compile your model before \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3980\u001b[0m                 \u001b[0;34m\"training/testing. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 프루닝된 모델 평가\n",
        "pruned_val_loss, pruned_val_accuracy = pruned_model.evaluate(X_val, y_val_categorical)\n",
        "pruned_test_loss, pruned_test_accuracy = pruned_model.evaluate(X_test, y_test_categorical)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "uX2PpLZD1Tm5",
        "outputId": "f216d422-cdd4-4de8-ae35-e4615178127c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-46853728ad2d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 프루닝된 모델 평가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpruned_val_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruned_val_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpruned_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpruned_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruned_test_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpruned_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3976\u001b[0m         \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3977\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3978\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   3979\u001b[0m                 \u001b[0;34m\"You must compile your model before \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3980\u001b[0m                 \u001b[0;34m\"training/testing. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 스트립 프루닝 적용\n",
        "pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)"
      ],
      "metadata": {
        "id": "edNnf1ghSwf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 프루닝된 모델 사이즈 확인 및 저장\n",
        "pruned_model.save('pruned_model.h5')\n",
        "pruned_model_size = os.path.getsize('pruned_model.h5') / (1024 * 1024)  # 모델 사이즈를 MB 단위로 변환\n",
        "print(f\"Pruned Model Size: {pruned_model_size:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "jUV4kP8j1Tpx",
        "outputId": "655942be-48ac-426d-e7f9-1a2cc450ac72"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'module_wrapper_99_input_ib-0'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-60d1976a3aaa>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 프루닝된 모델 사이즈 확인 및 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpruned_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pruned_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpruned_model_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pruned_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 모델 사이즈를 MB 단위로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Pruned Model Size: {pruned_model_size:.2f} MB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/functional.py\u001b[0m in \u001b[0;36mget_network_config\u001b[0;34m(network, serialize_layer_fn, config)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode_key\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mnew_node_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_conversion_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         model_inputs.append(\n\u001b[1;32m   1607\u001b[0m             \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_node_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'module_wrapper_99_input_ib-0'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 프루닝된 모델 메모리 사용량 확인\n",
        "pruned_memory_usage = process.memory_info().rss / (1024 * 1024)  # 메모리 사용량을 MB 단위로 변환\n",
        "print(f\"Pruned Memory Usage: {pruned_memory_usage:.2f} MB\")"
      ],
      "metadata": {
        "id": "Z4eVdKX41Tsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 프루닝된 모델 추론 시간 측정\n",
        "start_time = time.time()\n",
        "pruned_y_pred_categorical = pruned_model.predict(X_test)\n",
        "end_time = time.time()\n",
        "pruned_inference_time = end_time - start_time\n",
        "print(f\"Pruned Inference Time: {pruned_inference_time:.2f} seconds\")\n",
        "\n",
        "pruned_y_pred = np.argmax(pruned_y_pred_categorical, axis=1)"
      ],
      "metadata": {
        "id": "yiaDjcUm1TvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 혼동 행렬 및 성능 지표 출력 (검증 데이터)\n",
        "pruned_y_pred_val = pruned_model.predict(X_val)\n",
        "pruned_y_pred_val_classes = np.argmax(pruned_y_pred_val, axis=1)\n",
        "\n",
        "pruned_conf_matrix_val = confusion_matrix(y_val_encoded, pruned_y_pred_val_classes)\n",
        "pruned_class_report_val = classification_report(y_val_encoded, pruned_y_pred_val_classes, target_names=categories)\n",
        "\n",
        "print(\"Pruned Confusion Matrix (Validation):\")\n",
        "print(pruned_conf_matrix_val)\n",
        "print(\"\\nPruned Classification Report (Validation):\")\n",
        "print(pruned_class_report_val)"
      ],
      "metadata": {
        "id": "xXr1VbBi1TyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 혼동 행렬 및 성능 지표 출력 (테스트 데이터)\n",
        "pruned_conf_matrix_test = confusion_matrix(y_test_encoded, pruned_y_pred)\n",
        "pruned_class_report_test = classification_report(y_test_encoded, pruned_y_pred, target_names=categories)\n",
        "\n",
        "print(\"Pruned Confusion Matrix (Test):\")\n",
        "print(pruned_conf_matrix_test)\n",
        "print(\"\\nPruned Classification Report (Test):\")\n",
        "print(pruned_class_report_test)"
      ],
      "metadata": {
        "id": "RnOTC0j81T0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 양자화 인식 훈련(QAT) 적용\n",
        "def apply_qat(model):\n",
        "    quantize_model = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "    # 기존 모델을 양자화 모델로 래핑\n",
        "    qat_model = quantize_model(model)\n",
        "\n",
        "    # 양자화 모델 컴파일\n",
        "    qat_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "    return qat_model"
      ],
      "metadata": {
        "id": "iNMhjl-WC2Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 양자화 인식 훈련 모델 생성 및 재학습\n",
        "qat_model = apply_qat(pruned_model)\n",
        "qat_history = qat_model.fit(X_train, y_train_categorical, epochs=10, batch_size=32, validation_data=(X_val, y_val_categorical))"
      ],
      "metadata": {
        "id": "4CKLiSM2C6uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 양자화 인식 훈련 모델 평가\n",
        "qat_val_loss, qat_val_accuracy = qat_model.evaluate(X_val, y_val_categorical)\n",
        "qat_test_loss, qat_test_accuracy = qat_model.evaluate(X_test, y_test_categorical)"
      ],
      "metadata": {
        "id": "64UPiFc3DGZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 양자화 인식 훈련 모델 저장\n",
        "qat_model.save('qat_model.h5')\n",
        "\n",
        "# 양자화 인식 훈련 모델 스트립 프루닝 적용\n",
        "qat_model_stripped = tfmot.sparsity.keras.strip_pruning(qat_model)"
      ],
      "metadata": {
        "id": "QVpe6kk5DGcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 양자화 인식 훈련 모델 평가\n",
        "qat_val_loss_stripped, qat_val_accuracy_stripped = qat_model_stripped.evaluate(X_val, y_val_categorical)\n",
        "qat_test_loss_stripped, qat_test_accuracy_stripped = qat_model_stripped.evaluate(X_test, y_test_categorical)"
      ],
      "metadata": {
        "id": "qs43hcl7DGem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 양자화 인식 훈련 모델 사이즈 확인 및 저장\n",
        "qat_model_stripped.save('qat_model_stripped.h5')\n",
        "qat_model_size_stripped = os.path.getsize('qat_model_stripped.h5') / (1024 * 1024)  # 모델 사이즈를 MB 단위로 변환\n",
        "print(f\"QAT Model Size (Stripped): {qat_model_size_stripped:.2f} MB\")"
      ],
      "metadata": {
        "id": "3rS13312DGhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 양자화 인식 훈련 모델 메모리 사용량 확인\n",
        "qat_memory_usage = process.memory_info().rss / (1024 * 1024)  # 메모리 사용량을 MB 단위로 변환\n",
        "print(f\"QAT Memory Usage: {qat_memory_usage:.2f} MB\")"
      ],
      "metadata": {
        "id": "DLVT53ZyDGje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 양자화 인식 훈련 모델 추론 시간 측정\n",
        "start_time = time.time()\n",
        "qat_y_pred_categorical = qat_model_stripped.predict(X_test)\n",
        "end_time = time.time()\n",
        "qat_inference_time = end_time - start_time\n",
        "print(f\"QAT Inference Time: {qat_inference_time:.2f} seconds\")\n",
        "\n",
        "qat_y_pred = np.argmax(qat_y_pred_categorical, axis=1)"
      ],
      "metadata": {
        "id": "c4gFoeHLDUjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 혼동 행렬 및 성능 지표 출력 (검증 데이터)\n",
        "qat_y_pred_val = qat_model_stripped.predict(X_val)\n",
        "qat_y_pred_val_classes = np.argmax(qat_y_pred_val, axis=1)\n",
        "\n",
        "qat_conf_matrix_val = confusion_matrix(y_val_encoded, qat_y_pred_val_classes)\n",
        "qat_class_report_val = classification_report(y_val_encoded, qat_y_pred_val_classes, target_names=categories)\n",
        "\n",
        "print(\"QAT Confusion Matrix (Validation):\")\n",
        "print(qat_conf_matrix_val)\n",
        "print(\"\\nQAT Classification Report (Validation):\")\n",
        "print(qat_class_report_val)\n"
      ],
      "metadata": {
        "id": "G7RKaQSrDWFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 혼동 행렬 및 성능 지표 출력 (테스트 데이터)\n",
        "qat_conf_matrix_test = confusion_matrix(y_test_encoded, qat_y_pred)\n",
        "qat_class_report_test = classification_report(y_test_encoded, qat_y_pred, target_names=categories)\n",
        "\n",
        "print(\"QAT Confusion Matrix (Test):\")\n",
        "print(qat_conf_matrix_test)\n",
        "print(\"\\nQAT Classification Report (Test):\")\n",
        "print(qat_class_report_test)"
      ],
      "metadata": {
        "id": "Hg-X8BRBDXaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 양자화 모델 생성\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(qat_model_stripped)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_tflite_model = converter.convert()"
      ],
      "metadata": {
        "id": "Fegg8F-oDZSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 양자화된 모델 저장\n",
        "with open('quantized_model.tflite', 'wb') as f:\n",
        "    f.write(quantized_tflite_model)"
      ],
      "metadata": {
        "id": "whInjsccDZVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 양자화된 모델 사이즈 확인\n",
        "quantized_model_size = os.path.getsize('quantized_model.tflite') / (1024 * 1024)  # 모델 사이즈를 MB 단위로 변환\n",
        "print(f\"Quantized Model Size: {quantized_model_size:.2f} MB\")"
      ],
      "metadata": {
        "id": "rWpbLcJEDZX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 양자화된 모델 평가 함수 정의\n",
        "def evaluate_tflite_model(tflite_model_path, X_test, y_test_encoded):\n",
        "    # Load the TFLite model and allocate tensors\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Get input and output tensors\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # Test the model on the test data\n",
        "    input_shape = input_details[0]['shape']\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    all_preds = []\n",
        "\n",
        "    start_time = time.time()\n",
        "    for i in range(X_test.shape[0]):\n",
        "        input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "        predicted_label = np.argmax(output_data)\n",
        "        all_preds.append(predicted_label)\n",
        "        if predicted_label == y_test_encoded[i]:\n",
        "            correct_predictions += 1\n",
        "        total_predictions += 1\n",
        "    end_time = time.time()\n",
        "\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    inference_time = end_time - start_time\n",
        "    return accuracy, inference_time, all_preds"
      ],
      "metadata": {
        "id": "mZTLwTMeDZap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 양자화된 모델 평가 수행\n",
        "quantized_accuracy, quantized_inference_time, quantized_preds = evaluate_tflite_model('quantized_model.tflite', X_test, y_test_encoded)\n",
        "\n",
        "print(f\"Quantized Model Accuracy: {quantized_accuracy:.2f}\")\n",
        "print(f\"Quantized Model Inference Time: {quantized_inference_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "Sz5CmjpiDZdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 양자화된 모델 혼동 행렬 및 성능 지표 출력\n",
        "quantized_conf_matrix = confusion_matrix(y_test_encoded, quantized_preds)\n",
        "quantized_class_report = classification_report(y_test_encoded, quantized_preds, target_names=categories)\n",
        "\n",
        "print(\"Quantized Confusion Matrix (Test):\")\n",
        "print(quantized_conf_matrix)\n",
        "print(\"\\nQuantized Classification Report (Test):\")\n",
        "print(quantized_class_report)"
      ],
      "metadata": {
        "id": "bv4FiPREDgxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dt2X6kepDg66"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}